{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.data import *\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from PIL import Image\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('training/')\n",
    "\n",
    "path_lbl = path_data/'croppedLabels'\n",
    "path_img = path_data/'croppedImages'\n",
    "\n",
    "# get images and labels filenames\n",
    "img_names = get_image_files(path_img)\n",
    "lbl_names = get_image_files(path_lbl)\n",
    "\n",
    "print(len(img_names), len(lbl_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_lbl_fn(img_fn: Path):  \n",
    "  \n",
    "    img_name = img_fn.name\n",
    "    lbl_name = img_name\n",
    "\n",
    "    return img_fn.parent.parent/('croppedLabels/' + lbl_name)\n",
    "\n",
    "fname = Path('training/croppedImages/satImage_2_crop_2.png')\n",
    "\n",
    "img = open_image(fname)\n",
    "mask = open_mask(get_lbl_fn(fname))\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,6))\n",
    "\n",
    "img.show(ax[0])\n",
    "mask.show(ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes for segmentation with 0,255 labels:\n",
    "class SegLabelListCustom(SegmentationLabelList):\n",
    "    def open(self, fn):\n",
    "        return open_mask(fn, div=True)\n",
    "class SegItemListCustom(SegmentationItemList):\n",
    "    _label_cls = SegLabelListCustom\n",
    "\n",
    "bs = 4\n",
    "patch_shape = 16\n",
    "\n",
    "print(f'Batch size:{bs}')\n",
    "print(f'Patch shape:{patch_shape}')\n",
    "\n",
    "src = (SegItemListCustom.from_folder(\n",
    "    path_img).split_by_rand_pct().label_from_func(\n",
    "        lambda x: path_lbl / x.relative_to(path_img), classes=['rest',\n",
    "                                                               'road']))\n",
    "data = (src.transform(get_transforms(flip_vert=True),\n",
    "                      size=patch_shape,\n",
    "                      tfm_y=True).databunch(bs=bs).normalize(imagenet_stats))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_metric(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    return (input.argmax(dim=1)==target).float().mean()\n",
    "\n",
    "# weight decay\n",
    "wd = 1e-2\n",
    "#learning rate\n",
    "lr=1e-3\n",
    "\n",
    "# load the model, according to the data parameters (resolution, for example)\n",
    "learn = unet_learner(data, models.resnet34, metrics=acc_metric, wd=wd)\n",
    "\n",
    "#train the model with 3 epochs\n",
    "#learn.fit_one_cycle(3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('road_Resnet34')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# select one image from the validation dataset\n",
    "img = learn.data.valid_ds.x[22]\n",
    "mask = learn.data.valid_ds.y[22]\n",
    "pred = learn.predict(img)[0]\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(12,6))\n",
    "\n",
    "img.show(ax[0])\n",
    "mask.show(ax[1])\n",
    "pred.show(ax[2])\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictImage(img_path: Path, out_folder: Path):\n",
    "    '''\n",
    "    Predict the mask of an image and save the result in the wanted folder\n",
    "    :param img: path to the image to predict\n",
    "    :param out_folder: Path in which the image will be saved\n",
    "    '''\n",
    "    \n",
    "    img = load_image(img_path)\n",
    "    size = img.shape[1]\n",
    "    pred = []\n",
    "    cropped = img_crop(img,16,16)\n",
    "    imgss = []\n",
    "    numberOfPatches = (size//16)**2\n",
    "    for i in range(len(cropped)):\n",
    "        Image.fromarray((cropped[i] * 255).astype(np.uint8),'RGB').save(\"training/croppedPredictions/satImage_\"+str(i)+\"_crop\"+\".png\")   \n",
    "    for i in range(numberOfPatches):\n",
    "        im = open_image(\"training/croppedPredictions/satImage_\"+str(i)+\"_crop.png\")\n",
    "        pred.append(learn.predict(im)[0])\n",
    "        predmask = np.array([np.array(i.data) for i in pred])\n",
    "    predmask = predmask.reshape((numberOfPatches,16,16))\n",
    "    img = concatenate_mask(predmask, size)\n",
    "    if not (out_folder / img_path.name.replace(\".png\",\"_prediction.png\")).exists():\n",
    "        try:\n",
    "            (out_folder).mkdir()\n",
    "        except:\n",
    "            print(\"file exist\")\n",
    "        print(\"wenther\")\n",
    "    out = Image.fromarray((img * 255).astype(np.uint8),'L').save(out_folder / img_path.name.replace(\".png\",\"_prediction.png\"))   \n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_mask(cropped_masks,size):\n",
    "    '''\n",
    "    reassemble a nparray of mask to an Image\n",
    "    :param cropped_masks: nparray of shape(625,16,16) containing all cropped 16x16 masks\n",
    "    :return out: nparray of shape(400,400)\n",
    "    '''\n",
    "    w = size // 16\n",
    "    h = size // w\n",
    "    out = np.zeros((size, size))\n",
    "    for i in range(w):\n",
    "        columns = np.concatenate(cropped_masks[0 + i * w:w + i * w], axis=0)\n",
    "        out[:, 0 + i * h:h + i * h] = columns\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgToTest_path = Path('training/images/satImage_009.png')\n",
    "out = Path('training/Prediction/')\n",
    "predictedMask = predictImage(imgToTest_path, out )\n",
    "realmask = open_image('training/labels/satImage_009.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagetotest = open_image('training/images/satImage_009.png')\n",
    "realmask = open_image('training/labels/satImage_009.png')\n",
    "predictedMask = open_image('training/Prediction/satImage_009_prediction.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagetotest.show()\n",
    "#realmask.show()\n",
    "predictedMask.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgToTest_path = Path('test_set_images/test_set_images/test_4/test_4.png')\n",
    "out = Path('training/Prediction/')\n",
    "predictedMask = predictImage(imgToTest_path, out)\n",
    "#realmask = open_image('training/labels/satImage_009.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgToTest_path = Path('test_set_images/test_set_images/test_4/test_4.png')\n",
    "#realmask = open_image('training/labels/satImage_002.png')\n",
    "predictedMask = open_image('training/Prediction/test_4_prediction.png')\n",
    "imgtoTest = open_image(imgToTest_path)\n",
    "predictedMask.show()\n",
    "imgtoTest.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgtoTest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask_to_submission import *\n",
    "from tqdm import tqdm\n",
    "testPath = Path('test_set_images/test_set_images/')\n",
    "out = Path('test_set_images/predictions/')\n",
    "list_img = []\n",
    "def createSub(out_folder: Path, submission_file_name):\n",
    "    \n",
    "    for i in tqdm(range(50)):\n",
    "        \n",
    "        mask = predictImage(testPath / f\"test_{i+1}/test_{i+1}.png\", out/f\"test_{i+1}\")\n",
    "        list_img.append(Image.open(out / f\"test_{i+1}/test_{i+1}_prediction.png\"))\n",
    "    mask_to_submission(submission_file_name, list_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createSub(out, \"testsub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
