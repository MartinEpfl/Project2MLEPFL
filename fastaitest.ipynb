{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.data import *\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from PIL import Image\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('training/')\n",
    "\n",
    "path_lbl = path_data/'croppedLabels'\n",
    "path_img = path_data/'croppedImages'\n",
    "\n",
    "# get images and labels filenames\n",
    "img_names = get_image_files(path_img)\n",
    "lbl_names = get_image_files(path_lbl)\n",
    "\n",
    "print(len(img_names), len(lbl_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_lbl_fn(img_fn: Path):  \n",
    "  \n",
    "    img_name = img_fn.name\n",
    "    lbl_name = img_name\n",
    "\n",
    "    return img_fn.parent.parent/('croppedLabels/' + lbl_name)\n",
    "\n",
    "fname = Path('training/croppedImages/satImage_2_crop_2.png')\n",
    "\n",
    "img = open_image(fname)\n",
    "mask = open_mask(get_lbl_fn(fname))\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,6))\n",
    "\n",
    "img.show(ax[0])\n",
    "mask.show(ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes for segmentation with 0,255 labels:\n",
    "class SegLabelListCustom(SegmentationLabelList):\n",
    "    def open(self, fn):\n",
    "        return open_mask(fn, div=True)\n",
    "class SegItemListCustom(SegmentationItemList):\n",
    "    _label_cls = SegLabelListCustom\n",
    "\n",
    "bs = 4\n",
    "patch_shape = 16\n",
    "\n",
    "print(f'Batch size:{bs}')\n",
    "print(f'Patch shape:{patch_shape}')\n",
    "\n",
    "src = (SegItemListCustom.from_folder(\n",
    "    path_img).split_by_rand_pct().label_from_func(\n",
    "        lambda x: path_lbl / x.relative_to(path_img), classes=['rest',\n",
    "                                                               'road']))\n",
    "data = (src.transform(get_transforms(flip_vert=True),\n",
    "                      size=patch_shape,\n",
    "                      tfm_y=True).databunch(bs=bs).normalize(imagenet_stats))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_metric(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    return (input.argmax(dim=1)==target).float().mean()\n",
    "\n",
    "# weight decay\n",
    "wd = 1e-2\n",
    "#learning rate\n",
    "lr=1e-3\n",
    "\n",
    "# load the model, according to the data parameters (resolution, for example)\n",
    "learn = unet_learner(data, models.resnet34, metrics=acc_metric, wd=wd)\n",
    "\n",
    "#train the model with 3 epochs\n",
    "learn.fit_one_cycle(3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.save('road_Resnet34')\n",
    "\n",
    "# select one image from the validation dataset\n",
    "img = learn.data.valid_ds.x[22]\n",
    "mask = learn.data.valid_ds.y[22]\n",
    "pred = learn.predict(img)[0]\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(12,6))\n",
    "\n",
    "img.show(ax[0])\n",
    "mask.show(ax[1])\n",
    "pred.show(ax[2])\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_mask(list_masks):\n",
    "    \"\"\"list_masks of size (625, 16, 16) where the image \n",
    "    is assembled column after column so first 25 elements \n",
    "    are the first elements in the first column starting from pos [0,0] to [25,0]\n",
    "    masks are numpy of size (16,16)\"\"\"\n",
    "    z = np.zeros((400, 400))\n",
    "    for i in range(25):\n",
    "        columns = np.concatenate(list_masks[0 + i * 25:25 + i * 25], axis=0)\n",
    "        z[:, 0 + i * 16:16 + i * 16] = columns\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictImage(img):\n",
    "    pred = []\n",
    "    cropped = img_crop(img,16,16)\n",
    "    imgss = []\n",
    "    for i in range(len(cropped)):\n",
    "        Image.fromarray((cropped[i] * 255).astype(np.uint8),'RGB').save(\"training/croppedPredictions/satImage_\"+str(i)+\"_crop\"+\".png\")   \n",
    "    for i in range(625):\n",
    "        im = open_image(\"training/croppedPredictions/satImage_\"+str(i)+\"_crop.png\")\n",
    "        pred.append(learn.predict(im)[0])\n",
    "        predmask = np.array([np.array(i.data) for i in pred])\n",
    "    predmask = predmask.reshape((625,16,16))\n",
    "    img = concatenate_mask(predmask)\n",
    "    out = Image.fromarray((img * 255).astype(np.uint8),'L').save(\"training/Prediction/satImage.png\")   \n",
    "    return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagetotest = load_image('training/images/satImage_009.png')\n",
    "predictedMask = predictImage(imagetotest)\n",
    "realmask = open_image('training/labels/satImage_009.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagetotest = open_image('training/images/satImage_009.png')\n",
    "realmask = open_image('training/labels/satImage_009.png')\n",
    "predictedMask = open_image('training/Prediction/satImage.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagetotest.show()\n",
    "realmask.show()\n",
    "predictedMask.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagetotest = load_image('training/images/satImage_005.png')\n",
    "imagetotest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - np.min(img)\n",
    "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
    "    return rimg\n",
    "\n",
    "# Concatenate an image and its groundtruth\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = np.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# select one image from the validation dataset\n",
    "img = learn.data.valid_ds.x[21]\n",
    "mask = learn.data.valid_ds.y[21]\n",
    "pred = learn.predict(img)[0]\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(12,6))\n",
    "\n",
    "img.show(ax[0])\n",
    "mask.show(ax[1])\n",
    "pred.show(ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testimg = open_image('training/images/satImage_001.png')\n",
    "testimg.crop((0,0,200,200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff= fastai.vision.Image(testimg.px[0:16,0:16])\n",
    "pred = learn.predict(ff)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(learn.data.valid_ds.x[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_crop(im, w, h):\n",
    "    im = np.array(im.data)\n",
    "    list_patches = []\n",
    "    print(im.shape)\n",
    "    imgwidth = im.shape[1]\n",
    "    imgheight = im.shape[2]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[:,j:j+w, i:i+h]\n",
    "            list_patches.append(fastai.vision.Image(im_patch))\n",
    "    return list_patches\n",
    "def img_crop_2(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[1]\n",
    "    imgheight = im.shape[2]\n",
    "    print(imgwidth,imgheight)\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im.px[j:j+w, i:i+h]\n",
    "                \n",
    "            else:\n",
    "                im_patch = im.px[j:j+w, i:i+h, :]\n",
    "            list_patches.append(fastai.vision.Image(im_patch))\n",
    "    return list_patches\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - np.min(img)\n",
    "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
    "    return rimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predictOneImage(img):\n",
    "    pred = []\n",
    "    croppedImg = img_crop(img,16,16 )\n",
    "    for im in croppedImg:\n",
    "        pred.append(learn.predict(im))\n",
    "    return pred\n",
    "testimg = open_image('training/images/satImage_001.png')   \n",
    "patches = img_crop(testimg,16,16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_img(patches,patch_size):\n",
    "    j = []\n",
    "    for f in patches:\n",
    "        j.append(np.array(f.data)[0])\n",
    "    return fastai.vision.Image(np.array([item for sublist in j for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
