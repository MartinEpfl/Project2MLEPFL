{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.data import *\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from PIL import Image\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('training/')\n",
    "\n",
    "path_lbl = path_data/'croppedLabels'\n",
    "path_img = path_data/'croppedImages'\n",
    "\n",
    "# get images and labels filenames\n",
    "img_names = get_image_files(path_img)\n",
    "lbl_names = get_image_files(path_lbl)\n",
    "\n",
    "print(len(img_names), len(lbl_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_lbl_fn(img_fn: Path):  \n",
    "  \n",
    "    img_name = img_fn.name\n",
    "    lbl_name = img_name\n",
    "\n",
    "    return img_fn.parent.parent/('croppedLabels/' + lbl_name)\n",
    "\n",
    "fname = Path('training/croppedImages/satImage_2_crop_2.png')\n",
    "\n",
    "img = open_image(fname)\n",
    "mask = open_mask(get_lbl_fn(fname))\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,6))\n",
    "\n",
    "img.show(ax[0])\n",
    "mask.show(ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes for segmentation with 0,255 labels:\n",
    "class SegLabelListCustom(SegmentationLabelList):\n",
    "    def open(self, fn):\n",
    "        return open_mask(fn, div=True)\n",
    "class SegItemListCustom(SegmentationItemList):\n",
    "    _label_cls = SegLabelListCustom\n",
    "\n",
    "bs = 4\n",
    "patch_shape = 16\n",
    "\n",
    "print(f'Batch size:{bs}')\n",
    "print(f'Patch shape:{patch_shape}')\n",
    "\n",
    "src = (SegItemListCustom.from_folder(\n",
    "    path_img).split_by_rand_pct().label_from_func(\n",
    "        lambda x: path_lbl / x.relative_to(path_img), classes=['rest',\n",
    "                                                               'road']))\n",
    "data = (src.transform(get_transforms(flip_vert=True),\n",
    "                      size=patch_shape,\n",
    "                      tfm_y=True).databunch(bs=bs).normalize(imagenet_stats))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_metric(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    return (input.argmax(dim=1)==target).float().mean()\n",
    "\n",
    "# weight decay\n",
    "wd = 1e-2\n",
    "#learning rate\n",
    "lr=1e-3\n",
    "\n",
    "# load the model, according to the data parameters (resolution, for example)\n",
    "learn = unet_learner(data, models.resnet34, metrics=acc_metric, wd=wd)\n",
    "\n",
    "#train the model with 3 epochs\n",
    "learn.fit_one_cycle(3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.save('road_Resnet34')\n",
    "\n",
    "# select one image from the validation dataset\n",
    "img = learn.data.valid_ds.x[22]\n",
    "mask = learn.data.valid_ds.y[22]\n",
    "pred = learn.predict(img)[0]\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(12,6))\n",
    "\n",
    "img.show(ax[0])\n",
    "mask.show(ax[1])\n",
    "pred.show(ax[2])\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictImage(img):\n",
    "    pred = []\n",
    "    cropped = img_crop(img,16,16)\n",
    "    imgss = []\n",
    "    for i in range(len(cropped)):\n",
    "        Image.fromarray((cropped[i] * 255).astype(np.uint8),'RGB').save(\"training/croppedPredictions/satImage_\"+str(i)+\"_crop\"+\".png\")   \n",
    "    for i in range(625):\n",
    "        im = open_image(\"training/croppedPredictions/satImage_\"+str(i)+\"_crop.png\")\n",
    "        pred.append(learn.predict(im)[0])\n",
    "        predmask = np.array([np.array(i.data) for i in pred])\n",
    "    predmask = predmask.reshape((625,16,16))\n",
    "    img = concatenate_mask(predmask)\n",
    "    out = Image.fromarray((img * 255).astype(np.uint8),'L').save(\"training/Prediction/satImage.png\")   \n",
    "    return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagetotest = load_image('training/images/satImage_009.png')\n",
    "predictedMask = predictImage(imagetotest)\n",
    "realmask = open_image('training/labels/satImage_009.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagetotest = open_image('training/images/satImage_009.png')\n",
    "realmask = open_image('training/labels/satImage_009.png')\n",
    "predictedMask = open_image('training/Prediction/satImage.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagetotest.show()\n",
    "realmask.show()\n",
    "predictedMask.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
